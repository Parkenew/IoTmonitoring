input {
  kafka {
    bootstrap_servers => "{{MY_IP}}" 
    topics => ["seochoguinside_data"]
    group_id => "logstash_iot_group"
    codec => "json"
    auto_offset_reset => "earliest"
  }

}
filter {
  mutate {
    split => { "message" => "," }
  }

	mutate {
	  add_field => {
	    "datetime"             => "%{[message][0]}"
	    "pm10"                 => "%{[message][1]}"
	    "pm2_5"                => "%{[message][2]}"
	    "co2"                  => "%{[message][3]}"
	    "voc"                  => "%{[message][4]}"
	    "temperature"          => "%{[message][5]}"
	    "humidity"             => "%{[message][6]}"
	    "noise"                => "%{[message][7]}"
	    "comprehensive_index"  => "%{[message][8]}"
	    "serial_number"        => "%{[message][9]}"
	    "station_name"         => "%{[message][10]}"
	    "registration_date"    => "%{[message][11]}"
	    "latitude"             => "%{[message][12]}"
	    "longitude"            => "%{[message][13]}"
	    "customer"             => "%{[message][14]}"
	    "[geo_point][lat]"     => "%{[message][12]}"  
	    "[geo_point][lon]"     => "%{[message][13]}"  
	  }
	
	  convert => {
	    "latitude"  => "float"
	    "longitude" => "float"
	    "[geo_point][lat]" => "float"
	    "[geo_point][lon]" => "float"
	  }

	  remove_field => ["log", "ecs", "agent", "input", "host", "@version", "event", "message", "latitude", "longitude"]
	}
}
output {
  elasticsearch {
    hosts => ["{{MY_IP}}"]
    cacert => "/home/elastic/elasticsearch-8.13.3/config/certs/http_ca.crt"
    index => "seochoguinside_data"
    user => "elastic"
    password => "elastic"
  }
}
